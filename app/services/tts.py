from __future__ import annotations

import logging
import os
import re
import tempfile
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, TypedDict

import boto3
from botocore.exceptions import ClientError
from gtts import gTTS
from langchain.retrievers import EnsembleRetriever
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.retrievers import BM25Retriever
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from sqlalchemy.orm import Session

from app.core.config import settings
from app.repositories.research_repository import ResearchRepository
from app.repositories.tts_repository import TTSRepository

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===========================================================
# âœ… S3 ê¸°ë°˜ TTS ì„œë¹„ìŠ¤ (Legacy ë…ë¦½í˜•)
# ===========================================================


# Agent State Type
class AgentState(TypedDict, total=False):
    vectorstore: Any
    k: int
    summary: str
    explainer: str


def clean_text(text: str) -> str:
    """TTSìš© í…ìŠ¤íŠ¸ ì •ì œ"""
    cleaned = re.sub(r"[#*>â€¢\-]+", " ", text)
    cleaned = re.sub(r"\s+", " ", cleaned)
    return cleaned.strip()


class TTSService:
    def __init__(self, db: Session = None):
        self.db = db

        self.temp_dir = Path(settings.TEMP_DIR)
        self.output_dir = self.temp_dir / "tech11_tts"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.legacy_papers_dir = Path("legacy/downloaded_papers")

        # Initialize database repositories if db session provided
        self.research_repository = ResearchRepository(db) if db else None
        self.tts_repository = TTSRepository(db) if db else None

        # Initialize S3 client
        self.s3_client = None
        if settings.AWS_ACCESS_KEY and settings.AWS_SECRET_KEY:
            self.s3_client = boto3.client(
                "s3",
                aws_access_key_id=settings.AWS_ACCESS_KEY,
                aws_secret_access_key=settings.AWS_SECRET_KEY,
            )

    # =====================================================
    # 0ï¸âƒ£ S3 Helper Methods
    # =====================================================
    def _download_pdf_from_s3(self, filename: str) -> str:
        """Download PDF file from S3 bucket and return temporary file path"""
        # Validate S3 configuration
        if not settings.S3_BUCKET:
            raise ValueError(
                "S3_BUCKET environment variable is not configured. "
                "Please set S3_BUCKET in your environment variables."
            )
        if not self.s3_client:
            raise ValueError(
                "AWS credentials are not configured. "
                "Please set AWS_ACCESS_KEY and AWS_SECRET_KEY in your environment variables."
            )

        # Construct S3 key
        s3_key = f"output/research/{filename}"

        logger.info(f"ğŸ“¥ Downloading PDF from S3: s3://{settings.S3_BUCKET}/{s3_key}")

        try:
            # Check if file exists in S3
            self.s3_client.head_object(Bucket=settings.S3_BUCKET, Key=s3_key)
        except ClientError as e:
            error_code = e.response.get("Error", {}).get("Code", "")
            if error_code == "404":
                raise FileNotFoundError(
                    f"PDF file '{filename}' not found in S3 bucket. "
                    f"Expected location: s3://{settings.S3_BUCKET}/{s3_key}"
                )
            else:
                raise ValueError(f"Error accessing S3 file: {str(e)}")

        # Download PDF from S3 to temporary file
        try:
            # Create temporary file
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")

            # Download from S3
            self.s3_client.download_fileobj(settings.S3_BUCKET, s3_key, tmp)
            tmp.flush()
            tmp.close()

            logger.info("âœ… PDF downloaded successfully from S3")
            return tmp.name

        except Exception as e:
            # Clean up temporary file if it exists
            if tmp and os.path.exists(tmp.name):
                os.unlink(tmp.name)
            raise ValueError(f"Failed to download PDF from S3: {str(e)}")

    def _upload_audio_to_s3(self, local_file_path: str, filename: str) -> str:
        """Upload audio file to S3 bucket and return S3 URL"""
        if not settings.S3_BUCKET:
            raise ValueError("S3_BUCKET environment variable is not configured.")
        if not self.s3_client:
            raise ValueError("AWS credentials are not configured.")

        # Construct S3 key for TTS audio files
        s3_key = f"output/tts/{filename}"

        logger.info(f"ğŸ“¤ Uploading audio to S3: s3://{settings.S3_BUCKET}/{s3_key}")

        try:
            # Upload file to S3
            self.s3_client.upload_file(
                local_file_path,
                settings.S3_BUCKET,
                s3_key,
                ExtraArgs={"ContentType": "audio/mpeg"},
            )

            # Generate S3 URL
            s3_url = f"s3://{settings.S3_BUCKET}/{s3_key}"
            logger.info(f"âœ… Audio uploaded successfully to S3: {s3_url}")

            return s3_url

        except Exception as e:
            raise ValueError(f"Failed to upload audio to S3: {str(e)}")

    def _get_audio_url_from_s3(self, object_key: str) -> str | None:
        """Generate presigned URL for audio file in S3 using object_key"""
        if not settings.S3_BUCKET or not self.s3_client:
            return None

        try:
            # Check if file exists
            self.s3_client.head_object(Bucket=settings.S3_BUCKET, Key=object_key)

            # Generate presigned URL (valid for 1 hour)
            url = self.s3_client.generate_presigned_url(
                "get_object",
                Params={"Bucket": settings.S3_BUCKET, "Key": object_key},
                ExpiresIn=3600,
            )
            return url
        except ClientError:
            return None

    # =====================================================
    # 1ï¸âƒ£ LLM/Embeddings íŒ©í† ë¦¬ (Legacy í†µí•©)
    # =====================================================
    def _build_llm(self, use_mini: bool = True, temperature: float = 0.2):
        """Azure OpenAI LLM ìƒì„±"""
        return AzureChatOpenAI(
            openai_api_version="2024-02-01",
            azure_deployment=(
                settings.AOAI_DEPLOY_GPT4O_MINI
                if use_mini
                else settings.AOAI_DEPLOY_GPT4O
            ),
            api_key=settings.AOAI_API_KEY,
            azure_endpoint=settings.AOAI_ENDPOINT,
            temperature=temperature,
        )

    def _build_embeddings(self):
        """Azure OpenAI Embeddings ìƒì„±"""
        return AzureOpenAIEmbeddings(
            model=settings.AOAI_DEPLOY_EMBED_3_LARGE,
            openai_api_version="2024-02-01",
            api_key=settings.AOAI_API_KEY,
            azure_endpoint=settings.AOAI_ENDPOINT,
        )

    # =====================================================
    # 2ï¸âƒ£ PDF ì²˜ë¦¬ (Legacy í†µí•©)
    # =====================================================
    def _load_pdf(self, path: str) -> List[Document]:
        """PDF ë¡œë”©"""
        loader = PyMuPDFLoader(path)
        return loader.load()

    def _build_vectorstore(
        self, docs: List[Document], chunk_size: int = 1500, chunk_overlap: int = 300
    ):
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìœ„í•œ ë²¡í„°ìŠ¤í† ì–´ ë° ë¦¬íŠ¸ë¦¬ë²„ êµ¬ì¶• (FAISS + BM25)"""
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size, chunk_overlap=chunk_overlap
        )
        splits = splitter.split_documents(docs)

        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
        for d in splits:
            page = d.metadata.get("page", None)
            src = d.metadata.get("source", "")
            prefix = f"[source: {os.path.basename(src)} | page: {page}] "
            d.page_content = prefix + d.page_content

        # 1. FAISS ë²¡í„° ê²€ìƒ‰ (Dense Retrieval)
        embeddings = self._build_embeddings()
        faiss_vectorstore = FAISS.from_documents(splits, embeddings)
        faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={"k": 12})

        # 2. BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ (Sparse Retrieval)
        bm25_retriever = BM25Retriever.from_documents(splits)
        bm25_retriever.k = 12

        # 3. í•˜ì´ë¸Œë¦¬ë“œ ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„ (ê°€ì¤‘ì¹˜: FAISS 0.6, BM25 0.4)
        hybrid_retriever = EnsembleRetriever(
            retrievers=[faiss_retriever, bm25_retriever],
            weights=[0.6, 0.4],  # ë²¡í„° ê²€ìƒ‰ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
        )

        # ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ vectorstore ê°ì²´ì— hybrid_retriever ì¶”ê°€
        faiss_vectorstore.hybrid_retriever = hybrid_retriever

        return faiss_vectorstore

    # =====================================================
    # 3ï¸âƒ£ í”„ë¡¬í”„íŠ¸ ì²´ì¸ë“¤ (Legacy í†µí•©)
    # =====================================================
    def _make_summary_chain(self):
        """ìš”ì•½ ìƒì„± ì²´ì¸"""
        prompt = PromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ë…¼ë¬¸ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë¬¸ì„œë¥¼ ì½ê³  ë‹¤ìŒ í•­ëª©ì„ í¬í•¨í•´ ê°„ê²°í•˜ê³  êµ¬ì¡°í™”ëœ ìš”ì•½ì„ ì‘ì„±í•˜ì„¸ìš”.

1) í•œ ì¤„ ìš”ì•½
2) ì—°êµ¬ ë°°ê²½ê³¼ ë¬¸ì œ ì •ì˜
3) í•µì‹¬ ê¸°ìˆ ê³¼ ë°©ë²•ë¡ 
4) ì£¼ìš” ê²°ê³¼ì™€ ì„±ëŠ¥
5) ê¸°ìˆ ì  ì‹œì‚¬ì ê³¼ í•´ë‹¹ ë„ë©”ì¸ì„ ë„˜ì–´ AI ë° DT ì‹œì¥ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ë°©í–¥ ì œì‹œ
6) í•µì‹¬ í‚¤ì›Œë“œ ë‹¤ì‹œ í•œ ë²ˆ ì„¤ëª…. í•´ë‹¹ ë¬¸ì„œì˜ í•µì‹¬ ìš©ì–´ ë° ìƒˆë¡œìš´ ê°œë…ì— ëŒ€í•´ ì§šì–´ì£¼ê¸°.

ë¬¸ì„œ ë‚´ìš©:
{document_content}
"""
        )
        return prompt | self._build_llm(use_mini=True) | StrOutputParser()

    def _make_explainer_chain(self):
        """í•´ì„¤ ìƒì„± ì²´ì¸ - ì—´ì •ì ì¸ êµìœ¡ íŒŸìºìŠ¤íŠ¸ ìŠ¤íƒ€ì¼"""
        prompt = PromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ì—´ì •ì ì¸ êµìˆ˜ì´ì íŒŸìºìŠ¤íŠ¸ ì§„í–‰ìì…ë‹ˆë‹¤. ì²­ì·¨ìë“¤ì´ í¥ë¯¸ë¥¼ ê°€ì§€ê³  ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¹œê·¼í•˜ê³  êµ¬ì–´ì²´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.

**ì¤‘ìš”í•œ ê·œì¹™:**
- ì œëª©, í—¤ë”, ë²ˆí˜¸ ë§¤ê¸°ê¸°ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš” (ì˜ˆ: ###, ####, 1), 2) ë“±)
- ë§ˆí¬ë‹¤ìš´ í˜•ì‹(###, **, ---, #### ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ê´„í˜¸ ()ë¥¼ ìŠ¤í¬ë¦½íŠ¸ë¡œ ë§Œë“¤ì§€ ë§ê³ , ì„œìˆ ì„ í†µí•´ ë§í•´ì¤˜. ì˜ˆë¥¼ ë“¤ì–´ ê¸°ì¡´ì˜ 'LSTM(LongShortTermMemory)' ì„ 'LongShortTermMemoryë¡œ ë¶ˆë¦¬ìš°ëŠ” LSTMì€' ìœ¼ë¡œ ìˆ˜ì •
- "í•œêµ­ì–´ í•´ì„¤ ìŠ¤í¬ë¦½íŠ¸", "ë…¼ë¬¸ì˜ ìƒì„¸ ì„¤ëª…", "ì¼ë°˜ì¸ë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ ì„¤ëª…" ê°™ì€ ë©”íƒ€ ì •ë³´ë¥¼ ì“°ì§€ ë§ˆì„¸ìš”
- êµ¬ì–´ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (~í•´ìš”, ~ì´ì—ìš”, ~ê±°ë“ ìš”, ~ë„¤ìš”, ~ì–ì•„ìš” ë“±)
- íŒŸìºìŠ¤íŠ¸ì™€ ê°™ì€ ì»¨ì…‰ìœ¼ë¡œ, ì²­ì·¨ìì—ê²Œ ì§ì ‘ ë§í•˜ë“¯ì´ ì‘ì„±í•˜ì„¸ìš” ("ì—¬ëŸ¬ë¶„", "ìš°ë¦¬", "~í•´ë³¼ê¹Œìš”?", "~ë³´ì„¸ìš”" ë“±)
- ì—´ì •ì ì´ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- ë³µì¡í•œ ìš©ì–´ëŠ” ì¼ìƒì ì¸ ë¹„ìœ ë‚˜ ì˜ˆì‹œë¡œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”
- í•­ìƒ ì²« ì‹œì‘ ë¬¸ì¥ì€ 'ê°€ì¥ ì•ì„  ì„¸ìƒì„ ë°°ìš°ë‹¤, ì˜¤ëŠ˜ì˜ ì—ì´ì—‘ìŠ¤í”„ë ˆìŠ¤ ì‹œì‘í•©ë‹ˆë‹¤!'ë¡œ ì‹œì‘í•˜ê³ , íŒŸìºìŠ¤íŠ¸ djì²˜ëŸ¼ ì§„í–‰í•˜ëŠ” ê²ƒìœ¼ë¡œ í•´ì¤˜.

**ë‚´ìš© êµ¬ì„±:**
ìì—°ìŠ¤ëŸ¬ìš´ ì´ì•¼ê¸° íë¦„ìœ¼ë¡œ ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
1. ì—°êµ¬ ì£¼ì œë¥¼ í¥ë¯¸ë¡­ê²Œ ì†Œê°œí•˜ë©° ì‹œì‘. ë‹¤ë§Œ, ì²« ì†Œê°œì—ì„œëŠ” ì „ë¬¸ì ì¸ ìš©ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ ëª…í™•í•˜ê²Œ ë‚´ìš©ì„ ì „ë‹¬.
2. í•µì‹¬ ê°œë…ì„ ì‰¬ìš´ ë¹„ìœ ì™€ ì˜ˆì‹œë¡œ ì„¤ëª…
3. ìˆ˜ì‹ ë° ì‹¤í—˜ ê²°ê³¼ ì„¤ëª…ì— ëŒ€í•´ì„œëŠ” ëª…í™•í•˜ê²Œ ì „ë¬¸ ìš©ì–´ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ê²ƒ.
4. ì‹¤ì œ ì‚°ì—… í˜„ì¥ì—ì„œì˜ í™œìš© ì‚¬ë¡€ 2-3ê°€ì§€ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì†Œê°œ(ê°€ëŠ¥í•˜ë‹¤ë©´, AI ë° IT ì„œë¹„ìŠ¤ì™€ ì—°ê²°ì§€ìœ¼ë©´ ì¢‹ì„ ê²ƒ.)
5. ì´ ì—°êµ¬ì˜ ì˜ì˜ì™€ í•¨ê»˜ ì™œ ì´ ì—°êµ¬ê°€ ì¤‘ìš”í•œì§€ ë§ˆë¬´ë¦¬ë¡œ ì„¤ëª….

ë¬¸ì„œ ë‚´ìš©:
{document_content}

ì´ì œ ì²­ì·¨ìë“¤ì´ ì§‘ì¤‘í•˜ë©° ë“¤ì„ ìˆ˜ ìˆë„ë¡, ì¹œê·¼í•˜ê³  ì—´ì •ì ìœ¼ë¡œ ì„¤ëª…ì„ ì‹œì‘í•˜ì„¸ìš”:"""
        )
        return (
            prompt
            | self._build_llm(use_mini=False, temperature=0.5)
            | StrOutputParser()
        )

    # =====================================================
    # 4ï¸âƒ£ LangGraph ë…¸ë“œë“¤ (Legacy í†µí•©)
    # =====================================================
    def _node_summarizer(self, state: AgentState) -> AgentState:
        """ìš”ì•½ ìƒì„± ë…¸ë“œ - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©"""
        vs = state["vectorstore"]
        query = "summary overview of this document"

        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš© (FAISS + BM25)
        chunks = vs.hybrid_retriever.get_relevant_documents(query)
        content = "\n\n".join([c.page_content for c in chunks])

        logger.info("ğŸ“ ìš”ì•½ ìƒì„± ì¤‘... (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)")
        summary_chain = self._make_summary_chain()
        summary = summary_chain.invoke({"document_content": content})
        return {"summary": summary}

    def _node_explainer(self, state: AgentState) -> AgentState:
        """í•´ì„¤ ìƒì„± ë…¸ë“œ - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš©"""
        vs = state["vectorstore"]
        query = "detailed explanation with industry applications"

        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‚¬ìš© (FAISS + BM25)
        chunks = vs.hybrid_retriever.get_relevant_documents(query)
        content = "\n\n".join([c.page_content for c in chunks])

        logger.info("ğŸ“– í•´ì„¤ ìƒì„± ì¤‘... (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)")
        explainer_chain = self._make_explainer_chain()
        explainer = explainer_chain.invoke({"document_content": content})
        return {"explainer": explainer}

    # =====================================================
    # 5ï¸âƒ£ ë©€í‹°ì—ì´ì „íŠ¸ ì‹¤í–‰ (Legacy ë…ë¦½í˜•)
    # =====================================================
    async def _run_legacy_multi_agent(self, pdf_path: str) -> Dict[str, Any]:
        """
        Legacy ë…ë¦½í˜• ë©€í‹°ì—ì´ì „íŠ¸ ì‹¤í–‰
        PDF â†’ ë²¡í„°ìŠ¤í† ì–´ â†’ summary/explainer ìƒì„± (Legacy í´ë” ë¶ˆí•„ìš”)
        """
        try:
            logger.info(f"ğŸ¯ PDF ì²˜ë¦¬ ì‹œì‘: {pdf_path}")

            # 1. PDF ë¡œë“œ
            docs = self._load_pdf(pdf_path)
            logger.info(f"âœ… PDF ë¡œë“œ ì™„ë£Œ: {len(docs)}ê°œ ë¬¸ì„œ")

            # 2. ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•
            vs = self._build_vectorstore(docs)
            logger.info("âœ… ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ì™„ë£Œ")

            # 3. ìƒíƒœ ì´ˆê¸°í™”
            state: AgentState = {"vectorstore": vs, "k": 20}

            # 4. ìš”ì•½ ìƒì„±
            summary_result = self._node_summarizer(state)
            state.update(summary_result)

            # 5. í•´ì„¤ ìƒì„±
            explainer_result = self._node_explainer(state)
            state.update(explainer_result)

            logger.info("âœ… ë©€í‹°ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì™„ë£Œ")

            # 6. ê²°ê³¼ íŒŒì¼ ì €ì¥ (output/tts)
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            if state.get("summary"):
                summary_path = self.output_dir / f"summary_{ts}.txt"
                with open(summary_path, "w", encoding="utf-8") as f:
                    f.write(state["summary"])
                logger.info(f"ğŸ“ ìš”ì•½ ì €ì¥: {summary_path}")

            if state.get("explainer"):
                explainer_path = self.output_dir / f"explainer_{ts}.txt"
                with open(explainer_path, "w", encoding="utf-8") as f:
                    f.write(state["explainer"])
                logger.info(f"ğŸ“ í•´ì„¤ ì €ì¥: {explainer_path}")

            return {
                "summary": state.get("summary", ""),
                "explainer": state.get("explainer", ""),
                "quiz": "",  # TTSì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            }
        except Exception as e:
            logger.error(f"âŒ ë©€í‹°ì—ì´ì „íŠ¸ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise e

    # =====================================================
    # 2ï¸âƒ£ PDF â†’ ë©€í‹°ì—ì´ì „íŠ¸ â†’ TTS ë³€í™˜ ì „ì²´ íë¦„
    # =====================================================
    async def process_pdf_to_tts(self, pdf_path: str) -> Dict[str, Any]:
        """
        Legacy multitest.pyì˜ node_tts ë¡œì§ì„ ì •í™•íˆ ë”°ë¦„
        PDF â†’ ë©€í‹°ì—ì´ì „íŠ¸ â†’ explainerë§Œ TTS ë³€í™˜
        (Local file path version for backward compatibility)
        """
        try:
            # 1. ë©€í‹°ì—ì´ì „íŠ¸ ì‹¤í–‰ (legacy run_multi_agent í˜¸ì¶œ)
            logger.info(f"ğŸ“˜ Processing PDF: {pdf_path}")
            agent_result = await self._run_legacy_multi_agent(pdf_path)

            # 2. Legacy node_ttsì™€ ë™ì¼: explainerë§Œ ì‚¬ìš©
            script = agent_result.get("explainer", "")
            if not script:
                # Legacyì™€ ë™ì¼: explainerê°€ ì—†ìœ¼ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜
                return {
                    "summary": agent_result.get("summary", ""),
                    "explainer": "",
                    "tts_id": None,
                    "audio_filename": None,
                    "audio_file_path": None,
                }

            # 3. Legacy node_ttsì™€ ë™ì¼: clean_text ì ìš©
            script_clean = clean_text(script)

            # 4. Legacy node_ttsì™€ ë™ì¼: íŒŒì¼ëª… ìƒì„±
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            audio_filename = f"industry_explainer_{ts}.mp3"
            file_path = self.output_dir / audio_filename

            # 5. Legacy node_ttsì™€ ë™ì¼: gTTS ìƒì„± ë° ì €ì¥
            tts = gTTS(text=script_clean, lang="ko")
            tts.save(str(file_path))
            logger.info(f"ğŸ§ TTS ì €ì¥ ì™„ë£Œ: {audio_filename}")

            return {
                "summary": agent_result.get("summary", ""),
                "explainer": script,
                "tts_id": ts,
                "audio_filename": audio_filename,
                "audio_file_path": str(file_path),
            }

        except Exception as e:
            logger.error(f"âŒ PDF â†’ TTS ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise e

    async def process_pdf_from_s3_to_tts(self, filename: str) -> Dict[str, Any]:
        """
        S3 ê¸°ë°˜ PDF â†’ ë©€í‹°ì—ì´ì „íŠ¸ â†’ TTS ë³€í™˜ â†’ S3 ì—…ë¡œë“œ
        PDFë¥¼ S3ì—ì„œ ë‹¤ìš´ë¡œë“œ, ì²˜ë¦¬ í›„ TTSë¥¼ S3ì— ì—…ë¡œë“œ
        """
        temp_pdf_path = None
        temp_audio_path = None

        try:
            # 1. S3ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ
            logger.info(f"ğŸ“¥ Downloading PDF from S3: {filename}")
            temp_pdf_path = self._download_pdf_from_s3(filename)

            # 2. ë©€í‹°ì—ì´ì „íŠ¸ ì‹¤í–‰
            logger.info("ğŸ¤– Running multi-agent on PDF")
            agent_result = await self._run_legacy_multi_agent(temp_pdf_path)

            # 3. Explainer í…ìŠ¤íŠ¸ ì¶”ì¶œ
            script = agent_result.get("explainer", "")
            if not script:
                logger.warning("âš ï¸ No explainer text generated")
                return {
                    "summary": agent_result.get("summary", ""),
                    "explainer": "",
                    "tts_id": None,
                    "audio_filename": None,
                    "s3_url": None,
                    "presigned_url": None,
                }

            # 4. í…ìŠ¤íŠ¸ ì •ì œ
            script_clean = clean_text(script)

            # 5. TTS íŒŒì¼ëª… ìƒì„±
            ts = datetime.now().strftime("%Y%m%d_%H%M%S")
            audio_filename = f"industry_explainer_{ts}.mp3"

            # 6. ì„ì‹œ íŒŒì¼ë¡œ TTS ìƒì„±
            temp_audio_path = tempfile.NamedTemporaryFile(
                delete=False, suffix=".mp3"
            ).name
            tts = gTTS(text=script_clean, lang="ko")
            tts.save(temp_audio_path)
            logger.info(f"ğŸ§ TTS ìƒì„± ì™„ë£Œ: {audio_filename}")

            # 7. S3ì— TTS íŒŒì¼ ì—…ë¡œë“œ
            s3_url = self._upload_audio_to_s3(temp_audio_path, audio_filename)

            # 8. Presigned URL ìƒì„± (ë‹¤ìš´ë¡œë“œìš©)
            # Extract object_key from s3_url for presigned URL generation
            audio_object_key = s3_url.replace(f"s3://{settings.S3_BUCKET}/", "")
            presigned_url = self._get_audio_url_from_s3(audio_object_key)

            # 9. ë¡œì»¬ ì„ì‹œ íŒŒì¼ì—ë„ ì €ì¥ (ì„ íƒì‚¬í•­)
            local_file_path = self.output_dir / audio_filename
            os.rename(temp_audio_path, str(local_file_path))
            temp_audio_path = None  # ì´ë™í–ˆìœ¼ë¯€ë¡œ ì‚­ì œ ë°©ì§€

            return {
                "summary": agent_result.get("summary", ""),
                "explainer": script,
                "tts_id": ts,
                "audio_filename": audio_filename,
                "s3_url": s3_url,
                "presigned_url": presigned_url,
                "local_path": str(local_file_path),
            }

        except Exception as e:
            logger.error(f"âŒ S3 PDF â†’ TTS ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            raise e
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_pdf_path and os.path.exists(temp_pdf_path):
                os.unlink(temp_pdf_path)
                logger.info(f"ğŸ—‘ï¸ ì„ì‹œ PDF íŒŒì¼ ì‚­ì œ: {temp_pdf_path}")
            if temp_audio_path and os.path.exists(temp_audio_path):
                os.unlink(temp_audio_path)
                logger.info(f"ğŸ—‘ï¸ ì„ì‹œ TTS íŒŒì¼ ì‚­ì œ: {temp_audio_path}")

    # =====================================================
    # 3ï¸âƒ£ íŒŒì¼ ê¸°ë°˜ í—¬í¼ í•¨ìˆ˜ë“¤
    # =====================================================
    def get_audio_file_by_filename(self, filename: str) -> str | None:
        """ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
        file_path = self.output_dir / filename
        return str(file_path) if file_path.exists() else None

    def get_first_legacy_pdf(self) -> str | None:
        """legacy/downloaded_papers í´ë”ì˜ ì²« ë²ˆì§¸ PDF ë°˜í™˜"""
        pdf_files = list(self.legacy_papers_dir.glob("*.pdf"))
        return str(pdf_files[0]) if pdf_files else None

    # =====================================================
    # 4ï¸âƒ£ TTS íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë°
    # =====================================================
    def stream_audio_from_s3(self, object_key: str) -> tuple[bytes, str, dict]:
        """
        Stream audio file from S3 bucket using object_key
        Returns: (content_bytes, content_type, headers)
        """
        if not settings.S3_BUCKET:
            raise ValueError("S3_BUCKET environment variable is not configured.")
        if not self.s3_client:
            raise ValueError("AWS credentials are not configured.")

        logger.info(
            f"ğŸ§ Streaming audio from S3: s3://{settings.S3_BUCKET}/{object_key}"
        )

        try:
            # Get object from S3
            s3_obj = self.s3_client.get_object(
                Bucket=settings.S3_BUCKET, Key=object_key
            )
            content = s3_obj["Body"].read()

            # Determine content type
            import mimetypes

            # Extract filename from object_key for content type detection
            filename = object_key.split("/")[-1] if "/" in object_key else object_key
            content_type = (
                s3_obj.get("ContentType")
                or mimetypes.guess_type(filename)[0]
                or "application/octet-stream"
            )

            # Set headers
            headers = {"Content-Disposition": f'inline; filename="{filename}"'}

            logger.info(f"âœ… Audio streamed successfully from S3: {object_key}")
            return content, content_type, headers

        except ClientError as e:
            error_code = e.response.get("Error", {}).get("Code", "")
            if error_code == "NoSuchKey":
                raise FileNotFoundError(
                    f"ìŒì„± íŒŒì¼ '{object_key}'ì´ S3ì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
                )
            else:
                raise ValueError(f"S3 ì˜¤ë¥˜: {str(e)}")

    def stream_audio_by_research_id(self, research_id: int) -> tuple[bytes, str, dict]:
        """
        Stream audio file by research_id using database lookup
        Returns: (content_bytes, content_type, headers)
        """
        # Validate database session and repositories
        if not self.db or not self.tts_repository:
            raise ValueError(
                "Database session is required for research_id operations. "
                "Initialize TTSService with db parameter."
            )

        # 1. Retrieve TTS record from database
        logger.info(f"ğŸ” Looking up TTS for research ID: {research_id}")
        tts_record = self.tts_repository.get_by_research_id(research_id)

        if not tts_record:
            raise FileNotFoundError(
                f"TTS audio not found for research ID {research_id}. "
                "Please generate TTS first using POST /tts/ endpoint."
            )

        # 2. Validate object_key exists
        if not tts_record.object_key:
            raise ValueError(
                f"TTS record for research ID {research_id} is missing object_key. "
                "Cannot stream audio file."
            )

        # 3. Stream audio using object_key
        logger.info(f"ğŸ§ Streaming TTS audio for research ID: {research_id}")
        return self.stream_audio_from_s3(tts_record.object_key)

    # =====================================================
    # 5ï¸âƒ£ Research ID ê¸°ë°˜ TTS ìƒì„±
    # =====================================================
    async def create_tts_from_research_id(self, research_id: int) -> Dict[str, Any]:
        """Create TTS from research ID with caching logic"""
        try:
            # Validate database session and repositories
            if not self.db or not self.research_repository or not self.tts_repository:
                raise ValueError(
                    "Database session is required for research_id operations. "
                    "Initialize TTSService with db parameter."
                )

            # 1. Check cache first - look for existing TTS by research_id
            logger.info(f"ğŸ” Checking TTS cache for research ID: {research_id}")
            existing_tts = self.tts_repository.get_by_research_id(research_id)

            if existing_tts:
                logger.info(f"âœ… Found cached TTS for research ID: {research_id}")
                # Extract filename from object_key for presigned URL generation
                object_key = existing_tts.object_key
                filename = (
                    object_key.split("/")[-1] if "/" in object_key else object_key
                )

                # Generate presigned URL for the cached audio file
                presigned_url = self._get_audio_url_from_s3(object_key)

                return {
                    "id": existing_tts.id,
                    "research_id": existing_tts.research_id,
                    "summary": existing_tts.summary,
                    "explainer": existing_tts.explainer,
                    "audio_filename": filename,
                    "s3_url": f"s3://{settings.S3_BUCKET}/{object_key}",
                    "presigned_url": presigned_url,
                }

            # 2. No cache found - fetch research from database
            logger.info(f"ğŸ” No cache found. Fetching research with ID: {research_id}")
            research = self.research_repository.get_by_id(research_id)

            if not research:
                raise ValueError(f"Research with ID {research_id} not found")

            # 3. Validate research has object_key (S3 filename)
            if not research.object_key:
                raise ValueError(
                    f"Research with ID {research_id} does not have an associated PDF file (missing object_key)"
                )

            # 4. Extract filename from object_key
            # object_key format: "output/research/filename.pdf"
            research_object_key = research.object_key
            filename = (
                research_object_key.split("/")[-1]
                if "/" in research_object_key
                else research_object_key
            )

            logger.info(f"ğŸ“„ Using filename from research object_key: {filename}")

            # 5. Generate TTS using existing S3 method
            logger.info(f"ğŸ§ Generating new TTS for research ID: {research_id}")
            tts_result = await self.process_pdf_from_s3_to_tts(filename)

            # 6. Save TTS to database
            if tts_result.get("audio_filename") and tts_result.get("s3_url"):
                # Extract object_key from s3_url
                s3_url = tts_result["s3_url"]
                audio_object_key = s3_url.replace(f"s3://{settings.S3_BUCKET}/", "")

                tts_data = {
                    "research_id": research_id,
                    "summary": tts_result.get("summary", ""),
                    "explainer": tts_result.get("explainer", ""),
                    "object_key": audio_object_key,
                }

                saved_tts = self.tts_repository.create(tts_data)
                logger.info(f"âœ… TTS saved to database with ID: {saved_tts.id}")

                # Add tts_id to result
                tts_result["tts_id"] = saved_tts.id

            return tts_result

        except ValueError as e:
            logger.error(f"âŒ Research validation failed: {e}")
            raise e
        except Exception as e:
            logger.error(f"âŒ TTS generation from research ID failed: {e}")
            raise ValueError(f"TTS ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
