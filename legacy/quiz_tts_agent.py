import os
import re
import tempfile
import requests
from datetime import datetime
from typing import List, Dict, Any

# =====================================================================
# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.env ì‚¬ìš©)
# =====================================================================
from dotenv import load_dotenv
load_dotenv()  # .env íŒŒì¼ ì½ê¸°

# =====================================================================
# 2. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# =====================================================================
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import PyMuPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI

from gtts import gTTS   # Google Text-to-Speech

# =====================================================================
# 3. íŠ¹ìˆ˜ê¸°í˜¸ ì œê±° í•¨ìˆ˜
# =====================================================================
def clean_text(text: str) -> str:
    """
    TTSë¥¼ ìœ„í•´ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ê¸°í˜¸ë¥¼ ì œê±°í•˜ê³ 
    ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
    """
    # 1. ë§ˆí¬ë‹¤ìš´/ëª©ë¡ ê¸°í˜¸ ì œê±° (#, *, -, > ë“±)
    cleaned = re.sub(r"[#*>â€¢\-]+", " ", text)

    # 2. ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¤„ì„
    cleaned = re.sub(r"\s+", " ", cleaned)

    # 3. ì•ë’¤ ê³µë°± ì œê±°
    cleaned = cleaned.strip()

    return cleaned


# =====================================================================
# 4. PDFQuizSystem í´ë˜ìŠ¤
# =====================================================================
class PDFQuizSystem:
    def __init__(self):
        self.vectorstore = None
        self.summary = ""
        self.quiz = ""
        self.explainer = ""
        self.llm_mini = self.get_llm(temperature=0.2, use_mini=True)
        self.llm_full = self.get_llm(temperature=0.2, use_mini=False)
        self.embeddings = self.get_embeddings()

    # ------------------------
    # LLM & ì„ë² ë”©
    # ------------------------
    def get_llm(self, temperature: float = 0.2, use_mini: bool = True):
        return AzureChatOpenAI(
            openai_api_version="2024-02-01",
            azure_deployment=os.getenv("AOAI_DEPLOY_GPT4O_MINI") if use_mini else os.getenv("AOAI_DEPLOY_GPT4O"),
            temperature=temperature,
            api_key=os.getenv("AOAI_API_KEY"),
            azure_endpoint=os.getenv("AOAI_ENDPOINT"),
        )

    def get_embeddings(self):
        return AzureOpenAIEmbeddings(
            model=os.getenv("AOAI_DEPLOY_EMBED_3_LARGE"),
            openai_api_version="2024-02-01",
            api_key=os.getenv("AOAI_API_KEY"),
            azure_endpoint=os.getenv("AOAI_ENDPOINT"),
        )

    # ------------------------
    # PDF ë¡œë“œ
    # ------------------------
    def load_pdf(self, path_or_url: str):
        if path_or_url.startswith("http://") or path_or_url.startswith("https://"):
            resp = requests.get(path_or_url, timeout=30)
            resp.raise_for_status()
            tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".pdf")
            tmp.write(resp.content)
            tmp.flush()
            loader = PyMuPDFLoader(tmp.name)
            docs = loader.load()
            os.unlink(tmp.name)
        else:
            loader = PyMuPDFLoader(path_or_url)
            docs = loader.load()
        print(f"âœ… PDF ë¡œë“œ ì™„ë£Œ: {len(docs)}ê°œ ë¬¸ì„œ")
        return docs

    # ------------------------
    # ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•
    # ------------------------
    def build_vectorstore(self, docs, chunk_size=1000, chunk_overlap=200):
        splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
        splits = splitter.split_documents(docs)

        for d in splits:
            page = d.metadata.get("page", None)
            src = d.metadata.get("source", "")
            prefix = f"[source: {os.path.basename(src)} | page: {page}] "
            d.page_content = prefix + d.page_content

        vs = FAISS.from_documents(splits, self.embeddings)
        print(f"âœ… ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ì™„ë£Œ: {len(splits)}ê°œ ì²­í¬")
        return vs

    # ------------------------
    # 1ì°¨ ì—ì´ì „íŠ¸: ìš”ì•½
    # ------------------------
    def generate_summary(self, vectorstore):
        chunks = vectorstore.similarity_search("summary overview of this document", k=12)
        document_content = "\n\n".join([c.page_content for c in chunks])

        summary_prompt = """
ë‹¹ì‹ ì€ ë…¼ë¬¸ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë¬¸ì„œë¥¼ ì½ê³  ë‹¤ìŒê³¼ ê°™ì€ í•­ëª©ì„ í¬í•¨í•œ êµ¬ì¡°í™”ëœ ìš”ì•½ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.

ì²«ì§¸, í•œ ì¤„ ìš”ì•½
ë‘˜ì§¸, ì—°êµ¬ ë°°ê²½ê³¼ ë¬¸ì œ ì •ì˜
ì…‹ì§¸, í•µì‹¬ ê¸°ìˆ ê³¼ ë°©ë²•ë¡ 
ë„·ì§¸, ì£¼ìš” ê²°ê³¼ì™€ ì„±ëŠ¥
ë‹¤ì„¯ì§¸, ê¸°ìˆ ì  ì‹œì‚¬ì ê³¼ í•œê³„
ì—¬ì„¯ì§¸, í•µì‹¬ í‚¤ì›Œë“œ

ë¬¸ì„œ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
{document_content}

ì´ì œ í•œêµ­ì–´ ìš”ì•½ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""
        prompt_template = PromptTemplate.from_template(summary_prompt)
        summary_chain = prompt_template | self.llm_mini | StrOutputParser()
        summary = summary_chain.invoke({"document_content": document_content})
        print("âœ… í•œêµ­ì–´ ìš”ì•½ ì™„ë£Œ")
        return summary

    # ------------------------
    # 2ì°¨ ì—ì´ì „íŠ¸: í€´ì¦ˆ
    # ------------------------
    def generate_quiz(self, vectorstore):
        chunks = vectorstore.similarity_search("Generate exam questions based on this document", k=10)
        document_content = "\n\n".join([c.page_content for c in chunks])

        quiz_prompt = """
ë‹¹ì‹ ì€ ë…¼ë¬¸ ê¸°ë°˜ í€´ì¦ˆ ì œì‘ìì…ë‹ˆë‹¤. ì•„ë˜ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ í•œêµ­ì–´ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

ì¡°ê±´ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
ì´ ë‹¤ì„¯ ë¬¸í•­ì„ ë§Œë“¤ê³ , ê°ê´€ì‹, ì£¼ê´€ì‹, ì„œìˆ í˜•ì„ ì„ì–´ì„œ êµ¬ì„±í•©ë‹ˆë‹¤.
ê° ë¬¸í•­ì— ëŒ€í•´ ì •ë‹µê³¼ í•´ì„¤ì„ í•¨ê»˜ ì‘ì„±í•©ë‹ˆë‹¤.
ì œê³µí•  ë¬¸ì œì˜ ê²½ìš°ì—ëŠ”, ë…¼ë¬¸ì˜ ì €ì ë° ì‘ì„± ì‹œê¸° ë“±ê³¼ ê°™ì´ ì§€ì—½ì ì¸ ë¶€ë¶„ì€ í”¼í•˜ì„¸ìš”.
ê¸°ìˆ ê³¼ AI ë° ë…¼ë¬¸ì˜ í•µì‹¬ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 
ë§ˆì§€ë§‰ì—ëŠ” ìƒê°í•´ë³¼ ì˜ê²¬ ì„¸ ê°€ì§€ì™€ ì‹¤ë¬´ ì ìš© ë°©í–¥ ì„¸ ê°€ì§€ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.

ë¬¸ì„œ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
{document_content}

í€´ì¦ˆë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""
        prompt_template = PromptTemplate.from_template(quiz_prompt)
        quiz_chain = prompt_template | self.llm_mini | StrOutputParser()
        quiz = quiz_chain.invoke({"document_content": document_content})
        print("âœ… í€´ì¦ˆ ìƒì„± ì™„ë£Œ")
        return quiz

    # ------------------------
    # 3ì°¨ ì—ì´ì „íŠ¸: ì‚°ì—… ì ìš© í•´ì„¤
    # ------------------------
    def generate_industry_explainer(self, vectorstore):
        chunks = vectorstore.similarity_search("detailed explanation with industry applications", k=15)
        document_content = "\n\n".join([c.page_content for c in chunks])

        explainer_prompt = """
ë‹¹ì‹ ì€ ì „ë¬¸ í•´ì„¤ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë…¼ë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ í•´ì„¤ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ìŠ¤í¬ë¦½íŠ¸ëŠ” ì„¸ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ì²«ì§¸, ë…¼ë¬¸ì˜ ìƒì„¸ ì„¤ëª…
ë‘˜ì§¸, ì¼ë°˜ì¸ì´ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ í’€ì–´ì“´ í•´ì„¤
ì…‹ì§¸, ì‚°ì—… í˜„ì¥ì—ì„œ ì ìš©í•  ìˆ˜ ìˆëŠ” ë‘ì„¸ ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì œì‹œ

ë¬¸ì„œ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
{document_content}

ì´ì œ í•œêµ­ì–´ í•´ì„¤ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
"""
        prompt_template = PromptTemplate.from_template(explainer_prompt)
        explainer_chain = prompt_template | self.llm_full | StrOutputParser()
        script = explainer_chain.invoke({"document_content": document_content})
        print("âœ… ì‚°ì—… ì ìš© í•´ì„¤ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ")
        return script

    # ------------------------
    # TTS (íŒŸìºìŠ¤íŠ¸ ìƒì„±)
    # ------------------------
    def export_podcast(self, script: str, filename="podcast.mp3"):
        if not script:
            print("âŒ ë³€í™˜í•  ìŠ¤í¬ë¦½íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

        # ğŸ‘‡ íŠ¹ìˆ˜ê¸°í˜¸ ì œê±° ì ìš©
        script_clean = clean_text(script)

        tts = gTTS(text=script_clean, lang="ko")
        tts.save(filename)
        print(f"ğŸ§ íŒŸìºìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì™„ë£Œ: {filename}")
        return True

    # ------------------------
    # ì „ì²´ ì‹¤í–‰
    # ------------------------
    def process_pdf(self, pdf_path_or_url: str):
        print(f"\nğŸ¯ PDF ì²˜ë¦¬ ì‹œì‘: {pdf_path_or_url}")
        print("=" * 60)

        docs = self.load_pdf(pdf_path_or_url)
        self.vectorstore = self.build_vectorstore(docs)

        # ìš”ì•½
        print("\nğŸ“– 1ì°¨ ì—ì´ì „íŠ¸: í•œêµ­ì–´ ìš”ì•½")
        print("-" * 50)
        self.summary = self.generate_summary(self.vectorstore)
        print(self.summary)

        # í€´ì¦ˆ
        print("\nğŸ“ 2ì°¨ ì—ì´ì „íŠ¸: í€´ì¦ˆ ìƒì„±")
        print("-" * 50)
        self.quiz = self.generate_quiz(self.vectorstore)
        print(self.quiz)

        # ì‚°ì—… í•´ì„¤
        print("\nğŸ’¡ 3ì°¨ ì—ì´ì „íŠ¸: ì‚°ì—… ì ìš© í•´ì„¤ ìƒì„±")
        print("-" * 50)
        self.explainer = self.generate_industry_explainer(self.vectorstore)
        print(self.explainer)

        # ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        with open(f"summary_{timestamp}.txt", "w", encoding="utf-8") as f:
            f.write(self.summary)
        with open(f"quiz_{timestamp}.txt", "w", encoding="utf-8") as f:
            f.write(self.quiz)
        with open(f"explainer_{timestamp}.txt", "w", encoding="utf-8") as f:
            f.write(self.explainer)

        # íŒŸìºìŠ¤íŠ¸ íŒŒì¼ë¡œ ë³€í™˜
        self.export_podcast(self.explainer, f"industry_explainer_{timestamp}.mp3")

        print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥: summary_{timestamp}.txt, quiz_{timestamp}.txt, explainer_{timestamp}.txt, industry_explainer_{timestamp}.mp3")
        return True


# =====================================================================
# ì‹¤í–‰
# =====================================================================
if __name__ == "__main__":
    PDF_INPUT = "C:/Users/Administrator/Desktop/ì—°ìŠµ/2505.18397v3.pdf"
    system = PDFQuizSystem()
    system.process_pdf(PDF_INPUT)
